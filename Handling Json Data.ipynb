{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Handling Json Data (Basic)\n",
    "\n",
    "- 주제: 크롤링된 인별 데이터를 정제해보자.\n",
    "- 작성 날짜: 2018-07-09\n",
    "- 수정 날짜: 2018-07-09\n",
    "- 작성자: 부현경 (hyunkyung.boo@gmail.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd \n",
    "from pandas.io.json import json_normalize #package for flattening json in pandas df\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "# 로드할 파일 목록 불러오기\n",
    "def getPath(file_path, sign):\n",
    "    file_path_list = []\n",
    "    for (file_path, dir, files) in os.walk(path):\n",
    "        for filename in files:\n",
    "            ext = os.path.splitext(filename)[-1]\n",
    "            if ext == sign:\n",
    "                file_path_list.append(str(\"%s\\\\%s\" % (file_path, filename)))\n",
    "    return file_path_list\n",
    "            \n",
    "\n",
    "# 검색 태그명 추출하기\n",
    "def getKey(string):\n",
    "    tmp = string.split('\\\\')\n",
    "    result = tmp[len(tmp)-1].replace('.json', '')\n",
    "    return result\n",
    "\n",
    "\n",
    "# 딕셔너리로 구성된 데이터 중 키 값을 이용해 사용할 데이터(키-값)만을 추출하는 함수\n",
    "def extractItems(dict_data, keys):\n",
    "    new_dict = {}\n",
    "    for i in dict_data.keys():\n",
    "        if i in keys:\n",
    "            new_dict[i] = dict_data[i]\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\User\\Desktop\\\\InstagramCroller\"\n",
    "json_path_list = getPath(path, '.json')\n",
    "#print(1, json_path_list)\n",
    "\n",
    "All_df = pd.DataFrame()\n",
    "tag_count_list = []\n",
    "for path in json_path_list:\n",
    "    \n",
    "    # path = \"C:\\\\Users\\\\User\\Desktop\\\\InstagramCroller\\\\공연.json\"\n",
    "    with open(path, encoding='UTF8') as f:\n",
    "\n",
    "        # 1. load .Json\n",
    "        data = json.load(f)\n",
    "\n",
    "        # 2. Extract data (What will we use?)\n",
    "        keys = ['count', 'edges']\n",
    "        j1 = extractItems(data, keys)\n",
    "        \n",
    "        # 3. Normalize Json format\n",
    "        j2 = json_normalize(j1['edges'])\n",
    "\n",
    "        # 4. Drop columns that dont be needed and then rename columns\n",
    "        tmp = set(j2.columns)\n",
    "        fixed = set(['node.display_url', 'node.edge_liked_by.count', 'node.edge_media_to_caption.edges', \n",
    "                     'node.edge_media_to_comment.count', 'node.id', 'node.owner.id', 'node.taken_at_timestamp'])\n",
    "        removeColumnsSet = tmp - fixed\n",
    "        j2.drop(list(removeColumnsSet), axis = 1, inplace = True)\n",
    "        j2.columns = ['post_url', 'like_count', 'text', 'comment_count', 'post_id', 'user_id', 'time']\n",
    "\n",
    "        # 5. Extracing tags form text (use regex)\n",
    "        tag_list = []\n",
    "        for row in j2['text']:\n",
    "            if bool(row) == False:\n",
    "                tag_list.append(\"null+nan+none\")\n",
    "            #print(111, index)\n",
    "            else:\n",
    "                for index in row:\n",
    "                    row = str(index['node']['text'])\n",
    "                    if row.find(\"#\") > -1:\n",
    "                        p = re.compile('(#\\w*)')\n",
    "                        tag_from_row = p.findall(row)\n",
    "                        tag_from_row = [x.strip('#') for x in tag_from_row]\n",
    "                        row = ' '.join(tag_from_row)\n",
    "                        tag_list.append(row)\n",
    "                    else:\n",
    "                        tag_list.append(\"null+nan+none\")\n",
    "            \n",
    "        # 6. Create new columns and insert tag list into created columns\n",
    "        j2['tags'] = tag_list\n",
    "        # print(1, len(tag_list), len(j2), len(j2['text']))\n",
    "\n",
    "    tag_count_list.append([getKey(path), j1['count']])\n",
    "    All_df = All_df.append(j2)\n",
    "\n",
    "searching_tag_df = pd.DataFrame(tag_count_list, columns=['tag', 'count'])\n",
    "print(searching_tag_df, searching_tag_df.shape)\n",
    "print(All_df.tail(10),  All_df.shape)\n",
    "\n",
    "# Convert unix timestamp to this format of year/month/day/hh/mm/ss\n",
    "result_s = pd.to_datetime(All_df['time'],unit='s')\n",
    "All_df['time'] = result_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 저장\n",
    "save_path = \"D:\\\\defined_json_insta.xlsx\"\n",
    "writer = pd.ExcelWriter(save_path)\n",
    "All_df.to_excel(writer, 'combine_all_tags', header=True, index=False)\n",
    "searching_tag_df.to_excel(writer, 'tag+total_count', header=True, index=False)\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
