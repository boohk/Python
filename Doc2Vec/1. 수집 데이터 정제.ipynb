{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec\n",
    "- 작성 일시: 2018-06-08\n",
    "- 수정 일시: 2018-06-08\n",
    "- 작성자: 부현경 (hyunkyung.boo@gmail.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 수집된 데이터 정제\n",
    "- 수집된 데이터 합치고 DB에 데이터를 저장한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 엑셀 파일을 읽고 데이터 정제하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame()\n",
    "\n",
    "num_list = [1,2]\n",
    "for num in num_list:\n",
    "    load_path = \"D:\\\\naver_movie{}.xlsx\".format(num)\n",
    "    df = pd.read_excel(load_path, 'Sheet1')\n",
    "    # data_df.append(df)\n",
    "    data_df = pd.concat([data_df, df], axis = 0, ignore_index=True)\n",
    "    \n",
    "data_df = data_df.rename(columns = {0: 'post_id', 1: 'user_id', 2: 'movie_title', 3: 'user_review', \n",
    "                          4: 'user_rating', 5: 'post_date', 6: 'movie_genre', 7: 'running_time', \n",
    "                          8: 'release_date', 9: 'director', 10: 'actor', 11: 'movie_rating'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 중복 제거 후 해도되고 전에 해도된다. 사람 마음...이겠지..\n",
    "# release_date의 데이터 '개봉2018 . 05.01'의 형태를 '2018.05.01'로 바꿔준다.\n",
    "# 약 20만건 데이터이기 때문에 이렇게 정제하는 것은 시간이 오래걸린다. (-> 필자의 컴퓨터가 느려서 그런걸지도 모르지만.. ^^;;;)\n",
    "# 간단한 정제이기 때문에 엑셀의 데이터 나누기 기능을 쓰는 것이 빠르다.. (엑셀에서 20만건은 충분하다...)\n",
    "\n",
    "num = 0\n",
    "for r in data_df['release_date']:\n",
    "    r = str(r).replace(\"개봉\", \"\").replace(\" \", \"\")\n",
    "    print(num+1, r)\n",
    "    data_df['release_date'][num] = r\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row_data는 총 13개의 열로 구성되어 있으며 행은 195,917개이다.\n",
    "print(data_df.shape)\n",
    "\n",
    "# 중복 제거한 결과 행의 갯수가 118,773로 77,144건이 줄어들었다.\n",
    "drop_duplicated_df = dataType_added_df.drop_duplicates(['post_id'])\n",
    "print(drop_duplicated_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "defined_df = drop_duplicated_df.copy()\n",
    "# print(defined_df.shape)\n",
    "\n",
    "# 분할된 데이터의 각 그룹의 이름을 지정하는 함수.\n",
    "def addDataType(data, col_name, typeName):\n",
    "    df = pd.DataFrame(data)\n",
    "    df[col_name] = typeName\n",
    "    # 그룹별 형태를 확인한다. (행 갯수, 열 갯수)를 출력\n",
    "    print(df.shape)\n",
    "    return df\n",
    "\n",
    "# 새로 돌릴때마다 결과가 달라진다... 유의할 것\n",
    "# 학습/검증/테스트를 train, Validate, Test로 분리한다. (3:1:1 비율)\n",
    "train, validate, test = np.split(defined_df.sample(frac=1), [int(.6*len(defined_df)), int(.8*len(defined_df))])\n",
    "# print(train, validate, test)\n",
    "\n",
    "Train_df = addDataType(train, 'data_type', 'Train')\n",
    "Validate_df = addDataType(validate, 'data_type', 'Validate')\n",
    "Test_df = addDataType(test, 'data_type', 'Test')\n",
    "\n",
    "# 생성된 그룹들을 합친다.\n",
    "defined_df = pd.concat([Train_df, Validate_df, Test_df], axis = 0, ignore_index=True)\n",
    "\n",
    "print('레이블링한 결과', dataType_added_df.shape)\n",
    "print(dataType_added_df.sample(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_df.columns)\n",
    "# 백업용으로 앞서 합친 데이터를 저장한다.\n",
    "save_path = \"D:\\\\defined_naver_movie_information.xlsx\"\n",
    "writer = pd.ExcelWriter(save_path)\n",
    "dataType_added_df.to_excel(writer, 'Sheet1', header=True, index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 정제된 데이터를 DB에 저장하기\n",
    "- 미리 MySQL Workbench를 이용하여 테이블 및 열을 생성하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector.errors import Error\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    \n",
    "    # 사용자에 맞게 설정한다.\n",
    "    config = {\n",
    "        'user': 'user_ name',\n",
    "        'password': 'user_password',\n",
    "        'host': 'localhost',\n",
    "        'port': 3306,\n",
    "        'database': 'db_name',\n",
    "        'raise_on_warnings': True,\n",
    "        'charset' : 'utf8'\n",
    "    }\n",
    "\n",
    "    conn = mysql.connector.connect(**config)\n",
    "    curs = conn.cursor()\n",
    "    print(\"커넥션 성공!\")\n",
    "\n",
    "\n",
    "    # 생성된 열에 결과를 저장한다.\n",
    "    sql_insert_data = \"INSERT INTO naver_movie_info(data_type, post_id, user_id, movie_title, user_review, \\\n",
    "                        user_rating, post_date, movie_genre, running_time, realese_date, director, actor, movie_score) \\\n",
    "                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "    cnt = 0\n",
    "    total = 0\n",
    "    try:\n",
    "                \n",
    "        for row in dataType_added_df.iterrows():\n",
    "               \n",
    "            dt = row[1][12]\n",
    "            p_id = row[1][0]\n",
    "            u_id = row[1][1]\n",
    "            mt = row[1][2]\n",
    "            u_review = row[1][3]\n",
    "            u_rating = row[1][4]\n",
    "            pd = row[1][5] \n",
    "            mg = row[1][6]\n",
    "            \n",
    "            # 데이터 수집시 null값에 대해 nan처리가 되어\n",
    "            # 이는 MySql Table에 데이터 삽입시 오류를 발생시킨다.\n",
    "            # 이 때, NaN값을 \"\"으로 대체했다.\n",
    "            if str(row[1][6]) == \"nan\":\n",
    "                mg = \"\"\n",
    "                rt = \"\"\n",
    "                rd = \"\"\n",
    "                d = \"\"\n",
    "                a = \"\"\n",
    "                ms = \"\"\n",
    "                \n",
    "            else :\n",
    "                rt = row[1][7]\n",
    "                rd = row[1][8]\n",
    "                d = row[1][9]\n",
    "                a = row[1][10]\n",
    "                ms = row[1][11]\n",
    "            \n",
    "            values = (dt, p_id, u_id, mt, u_review, u_rating, pd, mg, rt, rd, d, a, ms)\n",
    "            curs.execute(sql_insert_data, values)\n",
    "            cnt = cnt + 1\n",
    "            print(cnt)\n",
    "            \n",
    "            if cnt == 50:\n",
    "                total += cnt\n",
    "                conn.commit()\n",
    "                cnt = 0\n",
    "\n",
    "        if cnt != 50:\n",
    "            print('마지막 commit 갯수: ', cnt)\n",
    "            total += cnt\n",
    "            conn.commit()\n",
    "\n",
    "    # SQL execute 등이 실패했을 때\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "# 디비 커넥션이 실패했을 때\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "finally:\n",
    "    print(\"Insert 갯수:\", total)\n",
    "    curs.close()\n",
    "    conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
