{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec\n",
    "## 5. Doc2Vec모델을 이용한 단어 시각화 및 클러스터링 (진행중)\n",
    "- 생성된 Doc2Vec 모델로 부터 Word Vector를 구해 PCA와 TSME를 사용해 시각화를 진행한다.\n",
    "- 생성된 모델은 총 \n",
    "- 작성 일시: 2018-06-11\n",
    "- 수정 일시: 2018-06-11\n",
    "- 작성자: 부현경 (hyunkyung.boo@gmail.com)\n",
    "- 참고:\n",
    "    1) PCA와 TSME\n",
    "    - https://programmers.co.kr/learn/courses/21/lessons/1698\n",
    "    - https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n",
    "    - https://www.journaldev.com/19279/python-gensim-word2vec\n",
    "    - http://bcho.tistory.com/1210\n",
    "    2) 한글 폰트 설정\n",
    "    - https://dojang.io/mod/page/view.php?id=1159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model_path_list = []\n",
    "for (path, dir, files) in os.walk(\"D:\\\\Doc2Vec_model_20180608\"):\n",
    "    for filename in files:\n",
    "        ext = os.path.splitext(filename)[-1]\n",
    "        if ext != '.npy':\n",
    "            model_path_list.append(str(\"%s\\\\%s\" % (path, filename)))\n",
    "            \n",
    "            \n",
    "# if os.path.isfile('questions-words.txt'):\n",
    "#     for model in word_models:\n",
    "#         sections = model.accuracy('questions-words.txt')\n",
    "#         correct, incorrect = len(sections[-1]['correct']), len(sections[-1]['incorrect'])\n",
    "#         print('%s: %0.2f%% correct (%d of %d)' % (model, float(correct*100)/(correct+incorrect), correct, correct+incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "\n",
    "def loadModel(model_path):\n",
    "    model = Doc2Vec.load(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "# 모든 단어의 위치 벡터\n",
    "def getWv(model):\n",
    "    vocab  = list(model.wv.vocab)\n",
    "    x = model[vocab]\n",
    "    return x\n",
    "\n",
    "\n",
    "# n개의 위치벡터값\n",
    "# getOpionalWv(model, \"김태리\", 15)\n",
    "def getOpionalWv(model, word, n):\n",
    "    sim_words = model.wv.most_similar(word, topn = n)\n",
    "    word_vec = []\n",
    "    # 자기 자신에 대한 유사도는 1이다.\n",
    "    first_element = word_vec.append(model[word])\n",
    "    for sw in sim_words:\n",
    "        word_vec.append(model[sw[0]])\n",
    "    return word_vec\n",
    "\n",
    "\n",
    "# n개의 위치벡터값과 각 키워드\n",
    "# getOpionalWv(model, \"김태리\", 15)\n",
    "def getOpionalWv_add_word(model, word, n):\n",
    "    sim_words = model.wv.most_similar(word, topn = n)\n",
    "    word_vec = []\n",
    "    # 자기 자신에 대한 유사도는 1이다.\n",
    "    first_element = word_vec.append(model[word])\n",
    "    for sw in sim_words:\n",
    "        word_vec.append([sw[0], model[sw[0]]])\n",
    "    return word_vec\n",
    "\n",
    "\n",
    "# 키워드, 유사도, 위치벡터값\n",
    "def getOpionalWv_add_sim(model, word, n):\n",
    "    sim_words = model.wv.most_similar(word, topn = n)\n",
    "    word_vec = []\n",
    "    # 자기 자신에 대한 유사도는 1이다.\n",
    "    first_element = [word, 1, model[word]]\n",
    "    word_vec.append(first_element)\n",
    "    for sw in sim_words:\n",
    "        word_vec.append([sw[0], sw[1], model[sw[0]]])\n",
    "    return word_vec\n",
    "\n",
    "\n",
    "# 축소된 차원수를 이용해 그림을 그린다.\n",
    "# def plot(result):\n",
    "#     # create a scatter plot of the projection\n",
    "#     pyplot.scatter(result[:, 0], result[:, 1])\n",
    "#     words = list(model.wv.vocab)\n",
    "#     for i, word in enumerate(words):\n",
    "#         pyplot.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "#     pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = []\n",
    "for m in model_path_list:\n",
    "    model_list.append(loadModel(m))\n",
    "# print(model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 그릴때 사용하는 패기지\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 폰트 설정\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "font_name = mpl.font_manager.FontProperties(fname='C:/Windows/Fonts/malgun.ttf').get_name()\n",
    "mpl.rc('font', family=font_name)\n",
    "# print (plt.rcParams['font.family'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. PCA를 사용한 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cnt = 0\n",
    "for model in model_list:\n",
    "    cnt += 1\n",
    "    vocab = list(model.wv.vocab)\n",
    "    X = model[vocab]\n",
    "#     print(len(X))\n",
    "#     print(X[0][:50])\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X[:50, :])\n",
    "    print(len(X_pca), X_pca)\n",
    "    df = pd.DataFrame(X_pca, index=vocab[:50], columns=['x', 'y'])\n",
    "    print(df.shape)\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(40, 20)\n",
    "    # 1,1,1은 subplotd의 그리드 인자를 정수 하나에 다 모아 표현한 것.\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.scatter(df['x'], df['y'])\n",
    "\n",
    "    for word, pos in df.iterrows():\n",
    "        ax.annotate(word, pos, fontsize=30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. TSNE을 사용한 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for model in model_list:\n",
    "    cnt += 1\n",
    "    vocab = list(model.wv.vocab)\n",
    "    X = model[vocab]\n",
    "    # print(len(X))\n",
    "    # print(X[0][:10])\n",
    "    tsne = TSNE(n_components=2)\n",
    "\n",
    "    X_tsne = tsne.fit_transform(X[:50,:])\n",
    "    # X_tsne = tsne.fit_transform(X)\n",
    "    \n",
    "    df = pd.DataFrame(X_tsne, index=vocab[:50], columns=['x', 'y'])\n",
    "    print(df.shape)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(40, 20)\n",
    "    # 1,1,1은 subplotd의 그리드 인자를 정수 하나에 다 모아 표현한 것.\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.scatter(df['x'], df['y'])\n",
    "\n",
    "    for word, pos in df.iterrows():\n",
    "        ax.annotate(word, pos, fontsize=30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
